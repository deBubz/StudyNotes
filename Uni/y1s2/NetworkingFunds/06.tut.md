# Week 6. Tutorial Problems

## P25. 

> We have said that an application may choose UDP for a transport protocol because UDP offers finer application control (than TCP) of what data is sent in a segment and when.

1. Why does an application have more control of what data is sent in a segment?
   - Theres a buffer
2. Why does an application have more control on when the segment is sent?
   - The app can controll when the segment is sent because of flow control

## P27

> Host A and B are communicating over a TCP connection, and Host B has already received from A all bytes up through byte 126. Suppose Host A then sends two segments to Host B back-to-back. The first and second segments contain 80 and 40 bytes of data, respectively.
> 
> In the first segment, the sequence number is 127, the source port number is 302, and the destination port number is 80. Host B sends an acknowledgment whenever it receives a segment from Host A.

1. In the second segment sent from Host A to B, what are the sequence number, source port number, and destination port number? `127` source `302` dest p `80`
2. If the first segment arrives before the second segment, in the acknowledgment of the first arriving segment, what is the acknowledgment number, the source port number, and the destination port number? source `80` destp `302` ack `207`
3. If the second segment arrives before the first segment, in the acknowledgment of the first arriving segment, what is the acknowledgment number? `127` > resend
4. Suppose the two segments sent by A arrive in order at B. The **first ACK is lost** and the second acknowledgment arrives after the first timeout interval. Draw a timing diagram, showing these segments and all other segments and acknowledgments sent. (Assume there is no additional packet loss.) For each segment in your figure, provide the sequence number and the number of bytes of data; for each acknowledgment that you add, provide the acknowledgment number. `247`

## P28

> Host A and B are directly connected with a 100 Mbps link (short link – propagation delay close to zero). There is one TCP connection between the two hosts, and Host A is sending to Host B an enormous file over this connection. Host A can send its application data into its TCP socket at a rate as high as 120 Mbps but Host B can read out of its TCP receive buffer at a maximum rate of 50 Mbps. Describe the effect of TCP flow control.

## P30

> Consider the network shown in Scenario 2 in Section 3.6.1. Suppose both sending hosts A and B have some fixed timeout values.

1. Argue that increasing the size of the finite buffer of the router might possibly decrease the throughput (λout).
2. Now suppose both hosts dynamically adjust their timeout values (like what TCP does) based on the buffering delay at the router. Would increasing the buffer size help to increase the throughput? Why?

## P+

> Host A and B are directly connected with a 10 Mbps link with a propagation delay of 10ms. Host A is sending to Host B an enormous file over a TCP connection. the TCP segment size is 1024Byte.

1. RcvBuffer is set at default value of 4096 bytes, what is the link utilization? what is the average TCP throughput from host A and Host B? (assuming no other traffic on the link, ignore other headers)
2. Assuming no other traffic on the link, what RcvBuffer needs to be at least in order to achieve a throughput of 10 Mbps?
3. Now assuming maximum RcvBuffer (calculated above) is used, but there is congestion caused by other traffic in the path. You observed that cwnd often reached 8192 bytes, before loss occurs. What is the rough average throughput now?
